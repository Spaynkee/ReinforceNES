{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helpful information\n",
    "# https://stable-baselines.readthedocs.io/en/master/guide/examples.html#using-callback-monitoring-training\n",
    "# actual rom files must be named rom.nes and placed in their specific folders... my path is:\n",
    "# /home/.local/lib/python3.6/site-packages/retro/data/stable/<GAME>/\n",
    "# Scenario files also go here, these are what determines how we reward the agent\n",
    "\n",
    "# To Do:\n",
    "# The plan was to try various baseline modesl and compare them, then\n",
    "# try to auto-optimize their parameters and compare again, then\n",
    "# if we had time try to put together one of our own and see how it compares to theirs.\n",
    "# Haven't yet had good luck with any models thus far.\n",
    "# Game List: SMB, Life Force, Megaman? Must be NES games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import retro\n",
    "import random\n",
    "import gym\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers.convolutional import Conv2D, Conv3D, Conv1D\n",
    "from keras.optimizers import Adam\n",
    "import os # for creating directories\n",
    "\n",
    "from stable_baselines.common.policies import MlpPolicy, CnnPolicy\n",
    "#from stable_baselines.deepq.policies import DQNPolicy\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines import PPO2, A2C, DQN\n",
    " # https://stable-baselines.readthedocs.io/en/master/guide/examples.html#using-callback-monitoring-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = retro.make(game=\"SuperMarioBros-Nes\")\n",
    "env = DummyVecEnv([lambda: env])  # The algorithms require a vectorized environment to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = DQN(DQNPolicy, env, verbose=1)\n",
    "model = PPO2(MlpPolicy, env, verbose=1)\n",
    "model.learn(total_timesteps=10000)\n",
    "model.save(\"savedModel\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading a model without an environment, this model cannot be trained until it has a valid environment.\n",
      "WARNING:tensorflow:From /home/kitchen/.local/lib/python3.6/site-packages/stable_baselines/common/input.py:26: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/kitchen/.local/lib/python3.6/site-packages/stable_baselines/common/policies.py:436: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/kitchen/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/kitchen/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# If you want to just load a model instead of retraining... we can use this to train on colossus\n",
    "model = PPO2.load(\"savedModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "for i in range(1000):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kitchen/.local/lib/python3.6/site-packages/retro/__init__.py\n"
     ]
    }
   ],
   "source": [
    "# To find out where to put .nes files\n",
    "print(retro.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see what games can be ran with little to no work.\n",
    "retro.data.list_games()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
